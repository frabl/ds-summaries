> Breiman, Leo. "Statistical modeling: The two cultures (with comments and a rejoinder by the author)." Statistical science 16.3 (2001): 199-231.

we have two opposing cultures with different assumptions.

_culture 1: statistical modeling SM / data modeling culture_

- assumption: data are generated by a stochastic data model.
- we try to find a matching stochastic data model (ie. linear regression, logistic regression, cox model) that returns the right response variables based on the given predictor variables, random noice, parameters.
  - the conclusions are based on the model’s outputs, not on that of the nature (original black box we are trying to model).
- model validation: goodness-of-fit tests.

_culture 2: machine learning ML / algorithmic modeling culture_

- assumption: data mechanism is unknown.
- we try to find a function, which is an algorithm that operates on the input data with neural nets / decision trees and tries to predict the response.
- model validation: measured by predictive accuracy.

the author thinks that SM people misunderstand ML people: occam's razor often gets interpreted as "simpler is better". but "simpler" (higher interpretability) usually always means lower accuracy. accuracy and simplicity are conflicting goals.

in essence: "an algorithmic model can produce more and more reliable information about the structure of the relationship between inputs and outputs than data models".

## critique

there are actually many counter examples of what has been said here: [“A systematic review shows no performance benefit of machine learning over logistic regression for clinical prediction models”](https://pubmed.ncbi.nlm.nih.gov/30763612/)

just because something is more complicated it isn't necessarily more accurate.
